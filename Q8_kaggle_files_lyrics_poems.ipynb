{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q8_kaggle_files_lyrics_poems.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "072d2ff3bed1449fa41f0a9f4b300959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b64a0f1d7e04865911be797075e2ec6",
              "IPY_MODEL_a3101f59de53447b84c87974a1dcb1b8",
              "IPY_MODEL_36ede457b1184341bcdfc85cc9309fc8"
            ],
            "layout": "IPY_MODEL_a6ccae8a9b68445282b0b9bb7339a274"
          }
        },
        "7b64a0f1d7e04865911be797075e2ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b6a975b97248db9478cb2f49a5a833",
            "placeholder": "​",
            "style": "IPY_MODEL_ae33d97c185142edb1030d75694e1793",
            "value": "Downloading: 100%"
          }
        },
        "a3101f59de53447b84c87974a1dcb1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5162932b8bef44ec8e023f1f701685b1",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3edbacbea0dc4915beef6e106f389510",
            "value": 1042301
          }
        },
        "36ede457b1184341bcdfc85cc9309fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40e2946890a04d2d93227d14f4b07b8a",
            "placeholder": "​",
            "style": "IPY_MODEL_4295ca918a304be9b805ae17f8241a2f",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 3.08MB/s]"
          }
        },
        "a6ccae8a9b68445282b0b9bb7339a274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b6a975b97248db9478cb2f49a5a833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae33d97c185142edb1030d75694e1793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5162932b8bef44ec8e023f1f701685b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3edbacbea0dc4915beef6e106f389510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40e2946890a04d2d93227d14f4b07b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4295ca918a304be9b805ae17f8241a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1814d54fd3e42c790214b51e8a0e814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8e9b9e626f14bc6aa4e37d02ce1ca69",
              "IPY_MODEL_a627d9b645f54be08163411d7542d55b",
              "IPY_MODEL_f7991a781f994f8ea7a7b29b94b47ccd"
            ],
            "layout": "IPY_MODEL_4adaa093999845ef8d28a14af356101b"
          }
        },
        "d8e9b9e626f14bc6aa4e37d02ce1ca69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b4bd29c30c941ee996b8bd9c0bea05d",
            "placeholder": "​",
            "style": "IPY_MODEL_483ad58928ca47878226651c4dc7ad41",
            "value": "Downloading: 100%"
          }
        },
        "a627d9b645f54be08163411d7542d55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fb378dabae498f9a1d29638dbfeed3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ce0e18534d4482588710a6034bde7da",
            "value": 456318
          }
        },
        "f7991a781f994f8ea7a7b29b94b47ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521f2c7cb8214d99b470eef109d0677f",
            "placeholder": "​",
            "style": "IPY_MODEL_687ed5c346764e2eb8db0b4c0af19bbf",
            "value": " 446k/446k [00:00&lt;00:00, 1.05MB/s]"
          }
        },
        "4adaa093999845ef8d28a14af356101b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b4bd29c30c941ee996b8bd9c0bea05d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483ad58928ca47878226651c4dc7ad41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17fb378dabae498f9a1d29638dbfeed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce0e18534d4482588710a6034bde7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "521f2c7cb8214d99b470eef109d0677f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687ed5c346764e2eb8db0b4c0af19bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c14bf981d9c24dcb831d27627f775e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9336b68fb3b42a4bda391492af2463d",
              "IPY_MODEL_1db43833ea3448b8a48f563b5c040366",
              "IPY_MODEL_908a2db0b1284b1d821f7a8cc0e79387"
            ],
            "layout": "IPY_MODEL_a466158d391749ad808ea9988df4625d"
          }
        },
        "f9336b68fb3b42a4bda391492af2463d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16f1e2c4e79041a8b6974be37d61b360",
            "placeholder": "​",
            "style": "IPY_MODEL_71b27d7f03a044d68b73291ef329434f",
            "value": "Downloading: 100%"
          }
        },
        "1db43833ea3448b8a48f563b5c040366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18e42d051f64a4abe5e14221c268d48",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1baa958933fd4126a084ae23476ef36c",
            "value": 665
          }
        },
        "908a2db0b1284b1d821f7a8cc0e79387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3289acea15f94fc899d5cb7a5ec08d9d",
            "placeholder": "​",
            "style": "IPY_MODEL_740c382a2509413d8941af214afa7772",
            "value": " 665/665 [00:00&lt;00:00, 20.2kB/s]"
          }
        },
        "a466158d391749ad808ea9988df4625d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f1e2c4e79041a8b6974be37d61b360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b27d7f03a044d68b73291ef329434f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c18e42d051f64a4abe5e14221c268d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1baa958933fd4126a084ae23476ef36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3289acea15f94fc899d5cb7a5ec08d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740c382a2509413d8941af214afa7772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanunjaya-varma/AttentionDrivenProjections/blob/master/Q8_kaggle_files_lyrics_poems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knfermA_Y3aB"
      },
      "outputs": [],
      "source": [
        "!unzip archive.zip -d archive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "filenames = os.listdir('archive/')\n",
        "print(filenames)\n",
        "# Open file3 in write mode\n",
        "with open('file3.txt', 'w') as outfile:\n",
        "  \n",
        "    # Iterate through list\n",
        "    for names in filenames:\n",
        "  \n",
        "        # Open each file in read mode\n",
        "        f = 'archive/' + names\n",
        "        with open(f) as infile:\n",
        "  \n",
        "            # read the data from file1 and\n",
        "            # file2 and write it in file3\n",
        "            outfile.write(infile.read())\n",
        "  \n",
        "        # Add '\\n' to enter data of file2\n",
        "        # from next line\n",
        "        outfile.write(\"\\n\")"
      ],
      "metadata": {
        "id": "XVeuJ6c5Y42W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23LuBRApca8n",
        "outputId": "6fcf2b4b-2f28-4e7e-aa9e-65f1babe5c31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 93657, done.\u001b[K\n",
            "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 93657 (delta 160), reused 182 (delta 122), pack-reused 93429\u001b[K\n",
            "Receiving objects: 100% (93657/93657), 85.83 MiB | 25.76 MiB/s, done.\n",
            "Resolving deltas: 100% (68669/68669), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/transformers\")\n",
        "os.chdir(\"./examples/pytorch/language-modeling\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrBu8eMlcnl1",
        "outputId": "8358cbfd-1973-452b-e85a-3960bb3e3df3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md\t  run_clm_no_trainer.py  run_mlm_no_trainer.py\trun_plm.py\n",
            "requirements.txt  run_clm.py\t\t run_mlm.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1MfJFQWJi8V",
        "outputId": "9c61c626-e577-4e34-fc6f-25a5865c87f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.7.1-py3-none-any.whl (79 kB)\n",
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 30 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 40 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 71 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 79 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.11.0+cu113)\n",
            "Collecting datasets>=1.8.0\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 18.4 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->-r requirements.txt (line 2)) (4.2.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 74.5 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.70.12.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.2 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 78.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (4.64.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.8.0->-r requirements.txt (line 3)) (3.0.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 77.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r requirements.txt (line 5)) (1.15.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 56.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.8.0->-r requirements.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2022.1)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, huggingface-hub, sentencepiece, datasets, accelerate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed accelerate-0.7.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 responses-0.18.0 sentencepiece-0.1.96 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHJcWok2OhPj",
        "outputId": "d14cc132-ed15-41eb-f09b-552f2597a7f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Collecting pyarrow\n",
            "  Downloading pyarrow-8.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.21.6)\n",
            "Installing collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 6.0.1\n",
            "    Uninstalling pyarrow-6.0.1:\n",
            "      Successfully uninstalled pyarrow-6.0.1\n",
            "Successfully installed pyarrow-8.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/huggingface/transformers/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIwfKwy0OuU-",
        "outputId": "0c9406db-8086-40c0-e4c9-0e4dabe6786f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers/\n",
            "  Cloning https://github.com/huggingface/transformers/ to /tmp/pip-req-build-fz882t4h\n",
            "  Running command git clone -q https://github.com/huggingface/transformers/ /tmp/pip-req-build-fz882t4h\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.5.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0.dev0) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0.dev0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2.10)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.19.0.dev0-py3-none-any.whl size=4103705 sha256=7839772c19dc0899797d1cceeb1acbfbf12008edd21b6432ced85c6b79f3e5e9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8nxh3yf7/wheels/fb/1b/91/0fcf504c386d427d65bbaf663eadf8e18cbf9795394ed7050d\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Now load the data line by line\n",
        "\"\"\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "with open('/content/file3.txt', 'r') as data:\n",
        "  dataset = [\"<|title|>\" + x.strip() for x in data.readlines()]\n",
        "\n",
        "train, eval = train_test_split(dataset, train_size=.9, random_state=2020)\n",
        "print(\"training size:\" + str(len(train)))\n",
        "print(\"Evaluation size: \" + str(len(eval)))\n",
        "\n",
        "with open('/content/train_tmp.txt', 'w') as file_handle:\n",
        "  file_handle.write(\"<|endoftext|>\".join(train))\n",
        "\n",
        "with open('/content/eval_tmp.txt', 'w') as file_handle:\n",
        "  file_handle.write(\"<|endoftext|>\".join(eval))"
      ],
      "metadata": {
        "id": "QBOaPflLPRGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4129397-1bd3-47ee-9b19-fed962ee37e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training size:168390\n",
            "Evaluation size: 18710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_clm.py \\\n",
        "--model_type gpt2-medium \\\n",
        "--model_name_or_path gpt2-medium \\\n",
        "--train_file \"/content/train_tmp.txt\" \\\n",
        "--do_train \\\n",
        "--validation_file \"/content/eval_tmp.txt\" \\\n",
        "--do_eval \\\n",
        "--per_gpu_train_batch_size 1 \\\n",
        "--save_steps -1 \\\n",
        "--num_train_epochs 5 \\\n",
        "--fp16 \\\n",
        "--output_dir=\"/content/pytorch_model/\"\\\n",
        "--overwrite_output_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnSRMTm97SGd",
        "outputId": "85881677-6cd3-4ba6-d9ee-2014320ff8ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/07/2022 06:41:24 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "05/07/2022 06:41:24 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/pytorch_model/--overwrite_output_dir/runs/May07_06-41-24_2566c49822a7,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=/content/pytorch_model/--overwrite_output_dir,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/pytorch_model/--overwrite_output_dir,\n",
            "save_on_each_node=False,\n",
            "save_steps=-1,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/07/2022 06:41:24 - WARNING - datasets.builder - Using custom data configuration default-4399354721d0dd4c\n",
            "05/07/2022 06:41:24 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "05/07/2022 06:41:24 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-4399354721d0dd4c/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n",
            "05/07/2022 06:41:24 - WARNING - datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-4399354721d0dd4c/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "05/07/2022 06:41:24 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-4399354721d0dd4c/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8\n",
            "100% 2/2 [00:00<00:00, 656.80it/s]\n",
            "[INFO|configuration_utils.py:659] 2022-05-07 06:41:24,668 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:708] 2022-05-07 06:41:24,669 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-medium\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:370] 2022-05-07 06:41:24,962 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:659] 2022-05-07 06:41:25,239 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:708] 2022-05-07 06:41:25,240 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-medium\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-05-07 06:41:27,251 >> loading file https://huggingface.co/gpt2-medium/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-05-07 06:41:27,251 >> loading file https://huggingface.co/gpt2-medium/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-05-07 06:41:27,251 >> loading file https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-05-07 06:41:27,251 >> loading file https://huggingface.co/gpt2-medium/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-05-07 06:41:27,251 >> loading file https://huggingface.co/gpt2-medium/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1782] 2022-05-07 06:41:27,251 >> loading file https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:659] 2022-05-07 06:41:27,537 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:708] 2022-05-07 06:41:27,538 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-medium\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-07 06:41:27,910 >> https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpea2ppb_2\n",
            "Downloading: 100% 1.42G/1.42G [00:32<00:00, 47.3MB/s]\n",
            "[INFO|hub.py:587] 2022-05-07 06:42:00,194 >> storing https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|hub.py:595] 2022-05-07 06:42:00,194 >> creating metadata file for /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|modeling_utils.py:1953] 2022-05-07 06:42:00,195 >> loading weights file https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|modeling_utils.py:2263] 2022-05-07 06:42:05,664 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:2272] 2022-05-07 06:42:05,665 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-medium.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Running tokenizer on dataset:   0% 0/1 [00:00<?, ?ba/s][WARNING|tokenization_utils_base.py:3412] 2022-05-07 06:42:13,734 >> Token indices sequence length is longer than the specified maximum sequence length for this model (2526081 > 1024). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|run_clm.py:393] 2022-05-07 06:42:13,734 >> ^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.\n",
            "05/07/2022 06:42:13 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-4399354721d0dd4c/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-b4082cd173995405.arrow\n",
            "Running tokenizer on dataset: 100% 1/1 [00:09<00:00,  9.07s/ba]\n",
            "Running tokenizer on dataset:   0% 0/1 [00:00<?, ?ba/s]05/07/2022 06:42:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-4399354721d0dd4c/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-a8a4940eeedebc2f.arrow\n",
            "Running tokenizer on dataset: 100% 1/1 [00:00<00:00,  1.18ba/s]\n",
            "Grouping texts in chunks of 1024:   0% 0/1 [00:00<?, ?ba/s]05/07/2022 06:42:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-4399354721d0dd4c/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-c71efba58ab64682.arrow\n",
            "Grouping texts in chunks of 1024: 100% 1/1 [00:02<00:00,  2.88s/ba]\n",
            "Grouping texts in chunks of 1024:   0% 0/1 [00:00<?, ?ba/s]05/07/2022 06:42:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-4399354721d0dd4c/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-6a1c7d55bf425d1e.arrow\n",
            "Grouping texts in chunks of 1024: 100% 1/1 [00:00<00:00,  3.33ba/s]\n",
            "05/07/2022 06:42:19 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/2.1.0/metrics/accuracy/accuracy.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpyog9tnns\n",
            "Downloading builder script: 3.19kB [00:00, 3.18MB/s]       \n",
            "05/07/2022 06:42:19 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/2.1.0/metrics/accuracy/accuracy.py in cache at /root/.cache/huggingface/datasets/downloads/4d12caaa6accab1bd606f17183717e0d5599de6efb3582bf3f02b0085a67f08d.6913c0dc30de3cef9d6bc88cc182661800cb937f0fe5b01ffa731617105a32ac.py\n",
            "05/07/2022 06:42:19 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/4d12caaa6accab1bd606f17183717e0d5599de6efb3582bf3f02b0085a67f08d.6913c0dc30de3cef9d6bc88cc182661800cb937f0fe5b01ffa731617105a32ac.py\n",
            "[INFO|trainer.py:461] 2022-05-07 06:42:32,315 >> Using amp half precision backend\n",
            "[WARNING|training_args.py:1011] 2022-05-07 06:42:32,321 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[WARNING|training_args.py:1011] 2022-05-07 06:42:32,321 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1294] 2022-05-07 06:42:32,335 >> ***** Running training *****\n",
            "[INFO|trainer.py:1295] 2022-05-07 06:42:32,335 >>   Num examples = 2466\n",
            "[INFO|trainer.py:1296] 2022-05-07 06:42:32,336 >>   Num Epochs = 5\n",
            "[INFO|trainer.py:1297] 2022-05-07 06:42:32,336 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1298] 2022-05-07 06:42:32,336 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1299] 2022-05-07 06:42:32,336 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1300] 2022-05-07 06:42:32,336 >>   Total optimization steps = 12330\n",
            "[WARNING|training_args.py:1011] 2022-05-07 06:42:32,344 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "{'loss': 2.6972, 'learning_rate': 4.799270072992701e-05, 'epoch': 0.2}\n",
            "{'loss': 2.5681, 'learning_rate': 4.596512570965126e-05, 'epoch': 0.41}\n",
            "{'loss': 2.5058, 'learning_rate': 4.3937550689375505e-05, 'epoch': 0.61}\n",
            "{'loss': 2.4695, 'learning_rate': 4.190997566909976e-05, 'epoch': 0.81}\n",
            "{'loss': 2.4122, 'learning_rate': 3.988240064882401e-05, 'epoch': 1.01}\n",
            "{'loss': 2.2376, 'learning_rate': 3.7854825628548256e-05, 'epoch': 1.22}\n",
            "{'loss': 2.227, 'learning_rate': 3.5827250608272504e-05, 'epoch': 1.42}\n",
            "{'loss': 2.2061, 'learning_rate': 3.379967558799676e-05, 'epoch': 1.62}\n",
            "{'loss': 2.2027, 'learning_rate': 3.177210056772101e-05, 'epoch': 1.82}\n",
            "{'loss': 2.1607, 'learning_rate': 2.9744525547445256e-05, 'epoch': 2.03}\n",
            "{'loss': 2.0325, 'learning_rate': 2.7716950527169504e-05, 'epoch': 2.23}\n",
            "{'loss': 2.0286, 'learning_rate': 2.5689375506893755e-05, 'epoch': 2.43}\n",
            "{'loss': 2.0181, 'learning_rate': 2.3661800486618003e-05, 'epoch': 2.64}\n",
            "{'loss': 2.0144, 'learning_rate': 2.1634225466342255e-05, 'epoch': 2.84}\n",
            "{'loss': 1.9816, 'learning_rate': 1.9606650446066503e-05, 'epoch': 3.04}\n",
            "{'loss': 1.8937, 'learning_rate': 1.7579075425790754e-05, 'epoch': 3.24}\n",
            "{'loss': 1.8937, 'learning_rate': 1.5555555555555555e-05, 'epoch': 3.45}\n",
            "{'loss': 1.8839, 'learning_rate': 1.3527980535279805e-05, 'epoch': 3.65}\n",
            "{'loss': 1.8807, 'learning_rate': 1.1500405515004056e-05, 'epoch': 3.85}\n",
            "{'loss': 1.8652, 'learning_rate': 9.472830494728304e-06, 'epoch': 4.06}\n",
            "{'loss': 1.8089, 'learning_rate': 7.445255474452554e-06, 'epoch': 4.26}\n",
            "{'loss': 1.8106, 'learning_rate': 5.417680454176805e-06, 'epoch': 4.46}\n",
            "{'loss': 1.8024, 'learning_rate': 3.3941605839416058e-06, 'epoch': 4.66}\n",
            "{'loss': 1.8006, 'learning_rate': 1.3665855636658558e-06, 'epoch': 4.87}\n",
            "100% 12330/12330 [2:08:46<00:00,  1.59it/s][INFO|trainer.py:1537] 2022-05-07 08:51:18,784 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 7726.4483, 'train_samples_per_second': 1.596, 'train_steps_per_second': 1.596, 'train_loss': 2.092134177153031, 'epoch': 5.0}\n",
            "100% 12330/12330 [2:08:46<00:00,  1.60it/s]\n",
            "[INFO|trainer.py:2213] 2022-05-07 08:51:18,786 >> Saving model checkpoint to /content/pytorch_model/--overwrite_output_dir\n",
            "[INFO|configuration_utils.py:446] 2022-05-07 08:51:18,787 >> Configuration saved in /content/pytorch_model/--overwrite_output_dir/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-07 08:51:24,640 >> Model weights saved in /content/pytorch_model/--overwrite_output_dir/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2108] 2022-05-07 08:51:24,641 >> tokenizer config file saved in /content/pytorch_model/--overwrite_output_dir/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2114] 2022-05-07 08:51:24,641 >> Special tokens file saved in /content/pytorch_model/--overwrite_output_dir/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        5.0\n",
            "  train_loss               =     2.0921\n",
            "  train_runtime            = 2:08:46.44\n",
            "  train_samples            =       2466\n",
            "  train_samples_per_second =      1.596\n",
            "  train_steps_per_second   =      1.596\n",
            "05/07/2022 08:51:24 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:2463] 2022-05-07 08:51:24,779 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-07 08:51:24,780 >>   Num examples = 273\n",
            "[INFO|trainer.py:2468] 2022-05-07 08:51:24,780 >>   Batch size = 8\n",
            "100% 35/35 [00:46<00:00,  1.04s/it]05/07/2022 08:52:14 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow\n",
            "100% 35/35 [00:48<00:00,  1.37s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        5.0\n",
            "  eval_accuracy           =      0.608\n",
            "  eval_loss               =     2.2029\n",
            "  eval_runtime            = 0:00:49.66\n",
            "  eval_samples            =        273\n",
            "  eval_samples_per_second =      5.497\n",
            "  eval_steps_per_second   =      0.705\n",
            "  perplexity              =     9.0509\n",
            "[WARNING|training_args.py:1011] 2022-05-07 08:52:14,447 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[WARNING|training_args.py:1011] 2022-05-07 08:52:14,447 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|modelcard.py:460] 2022-05-07 08:52:14,759 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6080299628686725}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFGPT2LMHeadModel\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"/content/pytorch_model/overwrite_output_dir/\", from_pt=True)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216,
          "referenced_widgets": [
            "072d2ff3bed1449fa41f0a9f4b300959",
            "7b64a0f1d7e04865911be797075e2ec6",
            "a3101f59de53447b84c87974a1dcb1b8",
            "36ede457b1184341bcdfc85cc9309fc8",
            "a6ccae8a9b68445282b0b9bb7339a274",
            "39b6a975b97248db9478cb2f49a5a833",
            "ae33d97c185142edb1030d75694e1793",
            "5162932b8bef44ec8e023f1f701685b1",
            "3edbacbea0dc4915beef6e106f389510",
            "40e2946890a04d2d93227d14f4b07b8a",
            "4295ca918a304be9b805ae17f8241a2f",
            "b1814d54fd3e42c790214b51e8a0e814",
            "d8e9b9e626f14bc6aa4e37d02ce1ca69",
            "a627d9b645f54be08163411d7542d55b",
            "f7991a781f994f8ea7a7b29b94b47ccd",
            "4adaa093999845ef8d28a14af356101b",
            "5b4bd29c30c941ee996b8bd9c0bea05d",
            "483ad58928ca47878226651c4dc7ad41",
            "17fb378dabae498f9a1d29638dbfeed3",
            "7ce0e18534d4482588710a6034bde7da",
            "521f2c7cb8214d99b470eef109d0677f",
            "687ed5c346764e2eb8db0b4c0af19bbf",
            "c14bf981d9c24dcb831d27627f775e15",
            "f9336b68fb3b42a4bda391492af2463d",
            "1db43833ea3448b8a48f563b5c040366",
            "908a2db0b1284b1d821f7a8cc0e79387",
            "a466158d391749ad808ea9988df4625d",
            "16f1e2c4e79041a8b6974be37d61b360",
            "71b27d7f03a044d68b73291ef329434f",
            "c18e42d051f64a4abe5e14221c268d48",
            "1baa958933fd4126a084ae23476ef36c",
            "3289acea15f94fc899d5cb7a5ec08d9d",
            "740c382a2509413d8941af214afa7772"
          ]
        },
        "id": "TMKA12wp9B0-",
        "outputId": "bf349d4b-680b-4016-c90b-6c7baa8649f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.12.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.23.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.15.attn.masked_bias', 'lm_head.weight', 'transformer.h.8.attn.masked_bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.21.attn.masked_bias']\n",
            "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "072d2ff3bed1449fa41f0a9f4b300959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1814d54fd3e42c790214b51e8a0e814"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c14bf981d9c24dcb831d27627f775e15"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(\"I love Deep Learning\", return_tensors='tf')"
      ],
      "metadata": {
        "id": "-BHpTpveSW3b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the tf tensor object\n",
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2PDPLrySZ59",
        "outputId": "00fc6647-6fa0-4090-cf55-4b8b2276e4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([   40,  1842, 10766, 18252], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text_samples = model.generate(\n",
        "    input_ids, \n",
        "    max_length=150,  \n",
        "    num_return_sequences=5,\n",
        "    no_repeat_ngram_size=2,\n",
        "    repetition_penalty=1.5,\n",
        "    top_p=0.92,\n",
        "    temperature=.85,\n",
        "    do_sample=True,\n",
        "    top_k=125\n",
        "    #early_stopping=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln7jFJhuSdht",
        "outputId": "f7eb49a2-b3e5-43d3-8eb7-da46cc5e7e2d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generated_text_samples.numpy\n",
        "output_list = list(generated_text_samples.numpy())\n",
        "s = ''\n",
        "for i in range(len(output_list)):\n",
        "  print(tokenizer.decode(output_list[i], skip_special_tokens=True))\n",
        "#print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29X_W1oTwApE",
        "outputId": "588775d9-b77e-46b1-9848-aa7682ac578a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love Deep Learning\n",
            "I love Deep Learning, deep learning Yeah\n",
            "I love Deep Learning so much\n",
            "I love Deep Learning\n",
            "I love Deep Learning, deep learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generated_text_samples.numpy\n",
        "output_list = list(generated_text_samples.numpy())\n",
        "s = ''\n",
        "for i in range(len(output_list)):\n",
        "  print(tokenizer.decode(output_list[i], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaOMPOu8w7ea",
        "outputId": "0c0a5aa9-7d87-403a-a3b3-6c32c7793de7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love Deep Learning\n",
            "I love Deep Learning\n",
            "I love Deep Learning\n",
            "I love Deep Learning\n",
            "I love Deep Learning, I'm so excited to work with you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generated_text_samples.numpy\n",
        "output_list = list(generated_text_samples.numpy())\n",
        "s = ''\n",
        "for i in range(len(output_list)):\n",
        "  print(tokenizer.decode(output_list[i], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D9XR9m3xI5F",
        "outputId": "d560d0d8-48c2-4ca1-f60e-01659961fbbc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love Deep Learning and machine learning\n",
            "I love Deep Learning\n",
            "I love Deep Learning\n",
            "I love Deep Learning, it's the future\n",
            "I love Deep Learning\n"
          ]
        }
      ]
    }
  ]
}